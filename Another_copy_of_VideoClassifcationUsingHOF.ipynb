{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "You should add this link to your google drive. Click the folder. https://drive.google.com/drive/folders/1O6FVKlGHagPeg3R5exvx1SHx96biEvpG?usp=sharing .In the top right, click Add a shortcut to My Drive.\n",
        "\n",
        "After finishing the hands on, download your notebook and submit it to the https://docs.google.com/forms/d/1s3lmt2sO_ky4RhtplMyD6I_42TGd8OA0NBnqU94P-ig/edit"
      ],
      "metadata": {
        "id": "zhq5ghyVt9zL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uqnZ3XhWvu60",
        "outputId": "d5e16c9c-3f4f-4527-c09a-9d49dd0e69b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qZDbc5nyqBHe"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import os\n",
        "from numpy import linalg as LA\n",
        "\n",
        "def getHOGHist(ang,mag):\n",
        "    feature_vector = []\n",
        "    hist_keys = np.array([0, 20, 40, 60, 80, 100, 120, 140, 160])\n",
        "    for i in range(0, 256, 8):\n",
        "        for j in range(0, 256, 8):\n",
        "\n",
        "            hist_vals = np.zeros(shape=hist_keys.size)\n",
        "\n",
        "            block_dir = ang[i:i + 8, j:j + 8]\n",
        "\n",
        "            block_mag = mag[i:i + 8, j:j + 8]\n",
        "\n",
        "            for row in range(0, 8):\n",
        "                for col in range(0, 8):\n",
        "                    mag_cell = block_mag[row, col]\n",
        "                    dir_cell = block_dir[row, col]\n",
        "\n",
        "                    for ind in range(1, 9):\n",
        "                        if (dir_cell <= hist_keys[ind]):\n",
        "                            ratio1 = ((hist_keys[ind] - dir_cell)/ 20)\n",
        "                            ratio2 = ((dir_cell - hist_keys[ind-1]) / 20)\n",
        "                            comp1 = ratio1 * mag_cell\n",
        "                            comp2 = ratio2 * mag_cell\n",
        "                            hist_vals[ind - 1] += comp1\n",
        "                            hist_vals[ind] += comp2\n",
        "                            break\n",
        "\n",
        "                    if dir_cell > 160:\n",
        "                        ratio1 = ((180 - dir_cell) / 20)\n",
        "                        ratio2 = ((dir_cell - 160) / 20)\n",
        "                        comp1 = ratio1 * mag_cell\n",
        "                        comp2 = ratio2 * mag_cell\n",
        "                        hist_vals[0] += comp1\n",
        "                        hist_vals[8] += comp2\n",
        "\n",
        "            feature_vector.append(hist_vals)\n",
        "\n",
        "    #print(len(feature_vector)) #1024 each consists of 1*9\n",
        "\n",
        "    feature_vector = np.reshape(feature_vector, (32, 32, 9))\n",
        "    features = []\n",
        "    for i in range(0, 31): #31 because output_size = image_size(32) - windowSize(2) + 1 when stride is 1\n",
        "        for j in range(0, 31):\n",
        "\n",
        "            hist_window = []\n",
        "            for cellIndexI in range(i, i + 2):\n",
        "                for cellIndexJ in range(j, j + 2):\n",
        "                    hist_cell = feature_vector[cellIndexI,cellIndexJ]\n",
        "                    hist_window.append(hist_cell)\n",
        "\n",
        "            hist_window = np.ravel(hist_window) #36*1\n",
        "            norm = LA.norm(hist_window)\n",
        "            hist_window = hist_window / norm\n",
        "\n",
        "            features.append(hist_window)\n",
        "\n",
        "    features = np.ravel(features).reshape(-1, 1)#(34596,1) which is 36*31*31\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def extract_features(cap):\n",
        "    video_features = []\n",
        "    ret, frame1 = cap.read()\n",
        "    prvs = cv.cvtColor(frame1, cv.COLOR_BGR2GRAY)\n",
        "    prvs = cv.resize(prvs, (256,256))\n",
        "\n",
        "    nFramesInCurrentVideo = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
        "    print('Number of frames in video: ', nFramesInCurrentVideo)\n",
        "    RequiredFrames = 20\n",
        "    frame_step = int(nFramesInCurrentVideo / RequiredFrames)\n",
        "    FrameIndex = frame_step\n",
        "    while FrameIndex <= nFramesInCurrentVideo:\n",
        "        cap.set(cv.CAP_PROP_POS_FRAMES, FrameIndex)\n",
        "        _, frame2 = cap.read()\n",
        "        next = cv.cvtColor(frame2, cv.COLOR_BGR2GRAY)\n",
        "        next = cv.resize(next, (256,256))\n",
        "        flow = cv.calcOpticalFlowFarneback(prvs, next, None, 0.7, 4, 12, 4, 6, 1.1, 0)\n",
        "        mag, ang = cv.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "        angle = ang * 180 / np.pi / 2\n",
        "        magnitude = cv.normalize(mag, None, 0, 255, cv.NORM_MINMAX)\n",
        "\n",
        "        currentFrameFeatures = getHOGHist(angle,magnitude)\n",
        "        video_features.append(currentFrameFeatures)\n",
        "\n",
        "        FrameIndex = FrameIndex + frame_step\n",
        "        prvs = next\n",
        "\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    return video_features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn import svm\n",
        "import pickle\n",
        "\n",
        "def train():\n",
        "\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "    folder_path = \"/content/drive/MyDrive/HOF/Training\"\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        cap = cv.VideoCapture(folder_path + '/' + file_name)\n",
        "        video_features = extract_features(cap)\n",
        "        label = 0 if \"walk\" in file_name else 1\n",
        "        video_labels = [label] * len(video_features)\n",
        "        all_features += video_features\n",
        "        all_labels += video_labels\n",
        "\n",
        "    NFrames = len(all_features)\n",
        "    all_features = np.array(all_features)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_features = np.squeeze(all_features, axis=2)\n",
        "    all_features = np.nan_to_num(all_features)\n",
        "    all_labels = all_labels.reshape(NFrames, 1)\n",
        "    clf = svm.SVC()\n",
        "    clf.fit(all_features, all_labels)\n",
        "    filename = 'trained_model.sav'\n",
        "    pickle.dump(clf, open(filename, 'wb'))\n",
        "\n",
        "\n",
        "def test():\n",
        "    folder_path = \"/content/drive/MyDrive/HOF/Testing\"\n",
        "    filename = \"/content/drive/MyDrive/HOF/trained_model.sav\"\n",
        "    loaded_model = pickle.load(open(filename, 'rb'))\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        cap = cv.VideoCapture(folder_path + '/' + file_name)\n",
        "        video_features = extract_features(cap)\n",
        "        NFrames = len(video_features)\n",
        "        yactual = 0 if \"walk\" in file_name else 1\n",
        "        video_labels = [yactual] * NFrames\n",
        "        video_features = np.array(video_features)\n",
        "        video_labels = np.array(video_labels)\n",
        "        video_features = np.squeeze(video_features, axis=2)\n",
        "        video_labels = video_labels.reshape(NFrames, 1)\n",
        "        video_features = np.nan_to_num(video_features)\n",
        "        prediction = loaded_model.predict(video_features)\n",
        "        predicted_label = np.round(np.mean(prediction))\n",
        "\n",
        "        print(\"Video: \" + file_name + \" Predicted Label: \" + str(\n",
        "            predicted_label) + \", Actual Label: \" + str(video_labels[0]))\n",
        "\n",
        "\n",
        "#train()\n",
        "test()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lvg-RHvxK312",
        "outputId": "963ac954-4dd0-434c-d7e2-4a73cf1d4c12"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator SVC from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of frames in video:  239\n",
            "Video: v_jumping_01_01.mpg Predicted Label: 1.0, Actual Label: [1]\n",
            "Number of frames in video:  106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-608c779f4809>:58: RuntimeWarning: invalid value encountered in divide\n",
            "  hist_window = hist_window / norm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video: v_jumping_01_04.mpg Predicted Label: 1.0, Actual Label: [1]\n",
            "Number of frames in video:  239\n",
            "Video: v_walk_dog_02_05.mpg Predicted Label: 0.0, Actual Label: [0]\n",
            "Number of frames in video:  214\n",
            "Video: v_walk_dog_15_01.mpg Predicted Label: 1.0, Actual Label: [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hHHhCCGUbZ3k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}