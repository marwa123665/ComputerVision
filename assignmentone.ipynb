{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectAndDescribe(image):\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        sift = cv2.xfeatures2d.SIFT_create()\n",
    "        (kps, features) = sift.detectAndCompute(gray, None)\n",
    "        \n",
    "        #kps = np.float32([kp.pt for kp in kps])\n",
    "        return (kps, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeMatches(imageA,imageB):\n",
    "\n",
    "    #for imageA, imageB in zip(a_images, b_images):\n",
    "        imageA = cv2.imread(imageA)\n",
    "        imageB = cv2.imread(imageB)\n",
    "\n",
    "        imageA = cv2.resize(imageA,(400,200))\n",
    "        imageB = cv2.resize(imageB,(400,200))\n",
    "\n",
    "        (kpsA, descriptorA) = detectAndDescribe(imageA)\n",
    "        (kpsB, descriptorB) = detectAndDescribe(imageB)\n",
    "\n",
    "        # match features between the two images\n",
    "        matcher = cv2.BFMatcher()\n",
    "        rawMatches =matcher.knnMatch(descriptorA, descriptorB, 2)\n",
    "        matches_backward = matcher.knnMatch(descriptorB, descriptorA, 2)\n",
    "\n",
    "\n",
    "        matches = []\n",
    "        ratio = 0.7\n",
    "        \n",
    "        #David Lowe's ratio test and cross-checking\n",
    "        for m,n in rawMatches:\n",
    "            if m.distance<(ratio*n.distance):\n",
    "                for mm, nn in matches_backward:\n",
    "                    if mm.trainIdx == m.queryIdx and mm.queryIdx == m.trainIdx:\n",
    "                        matches.append(m)\n",
    "                        break\n",
    "        matchesMask=None\n",
    "        #apply the ransac mask to the matches    \n",
    "        if len(matches) >=4:\n",
    "            ptsA = np.float32([kpsA[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "            ptsB = np.float32([kpsB[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "            \n",
    "            (H, mask) = cv2.findHomography(ptsA, ptsB, cv2.RANSAC,20)\n",
    "            \n",
    "            matchesMask = mask.ravel().tolist()\n",
    "            print(\"matchesMask: \", len(matchesMask))\n",
    "        \n",
    "       \n",
    "    \n",
    "        #3- Threshold based on distance. (The distance must not be constant and should be derived from an analysis of the data distribution)\n",
    "        # if len(matches) > 0:\n",
    "        #     distances = [m.distance for m in matches]\n",
    "            \n",
    "        #     median_distance = np.median(distances)\n",
    "        #     threshold = median_distance\n",
    "        #     matches = [m for m in matches if m.distance < threshold]    \n",
    "\n",
    "        #4- Draw the matches on the images and display the images\n",
    "\n",
    "\n",
    "        similarity_score = len(matches) / min(len(kpsA), len(kpsB))\n",
    "    \n",
    "        if similarity_score > 0.2:\n",
    "            print(\"The images are similar\")\n",
    "            \n",
    "        else:\n",
    "            print(\"The images are not similar\")\n",
    "        print(\"similarity score: \", similarity_score)\n",
    "        #result = cv2.drawMatches(imageA, kpsA, imageB, kpsB, matches, None)\n",
    "        #cv2.line(result, (0, 200), (400, 200), (0, 0, 255), 2)\n",
    "        #cv2.imshow(\"result\", result)\n",
    "        print(\"matches: \", len(matches))\n",
    "        if matchesMask!=None and len(matches)==len(matchesMask)  :   \n",
    "            result=cv2.drawMatches(imageA,kpsA,imageB,kpsB,matches,None,\n",
    "                            matchesMask=matchesMask,# draw only inliers\n",
    "                            flags=2)\n",
    "            cv2.imshow(\"result\", result)\n",
    "\n",
    "        cv2.imshow(\"imageA\",imageA)\n",
    "        cv2.imshow(\"imageB\",imageB)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:/Users/marwa/Downloads/CV Labs/assignment data-20240329T203755Z-001/assignment data\\\\image1a.jpeg', 'C:/Users/marwa/Downloads/CV Labs/assignment data-20240329T203755Z-001/assignment data\\\\image1b.jpeg', 'C:/Users/marwa/Downloads/CV Labs/assignment data-20240329T203755Z-001/assignment data\\\\image2a.jpeg', 'C:/Users/marwa/Downloads/CV Labs/assignment data-20240329T203755Z-001/assignment data\\\\image2b.jpeg', 'C:/Users/marwa/Downloads/CV Labs/assignment data-20240329T203755Z-001/assignment data\\\\image3a.jpeg', 'C:/Users/marwa/Downloads/CV Labs/assignment data-20240329T203755Z-001/assignment data\\\\image3b.jpeg', 'C:/Users/marwa/Downloads/CV Labs/assignment data-20240329T203755Z-001/assignment data\\\\image4a.jpeg', 'C:/Users/marwa/Downloads/CV Labs/assignment data-20240329T203755Z-001/assignment data\\\\image4b.jpeg', 'C:/Users/marwa/Downloads/CV Labs/assignment data-20240329T203755Z-001/assignment data\\\\image4c.png', 'C:/Users/marwa/Downloads/CV Labs/assignment data-20240329T203755Z-001/assignment data\\\\image5a.jpeg', 'C:/Users/marwa/Downloads/CV Labs/assignment data-20240329T203755Z-001/assignment data\\\\image5b.jpeg', 'C:/Users/marwa/Downloads/CV Labs/assignment data-20240329T203755Z-001/assignment data\\\\image6a.jpeg', 'C:/Users/marwa/Downloads/CV Labs/assignment data-20240329T203755Z-001/assignment data\\\\image6b.jpeg', 'C:/Users/marwa/Downloads/CV Labs/assignment data-20240329T203755Z-001/assignment data\\\\image7a.jpeg', 'C:/Users/marwa/Downloads/CV Labs/assignment data-20240329T203755Z-001/assignment data\\\\image7b.jpeg']\n",
      "The images are not similar\n",
      "similarity score:  0.006134969325153374\n",
      "matches:  2\n",
      "matchesMask:  49\n",
      "The images are not similar\n",
      "similarity score:  0.14803625377643503\n",
      "matches:  49\n",
      "The images are not similar\n",
      "similarity score:  0.014218009478672985\n",
      "matches:  3\n",
      "matchesMask:  129\n",
      "The images are similar\n",
      "similarity score:  0.49236641221374045\n",
      "matches:  129\n",
      "matchesMask:  137\n",
      "The images are similar\n",
      "similarity score:  0.4807017543859649\n",
      "matches:  137\n",
      "matchesMask:  125\n",
      "The images are similar\n",
      "similarity score:  0.4770992366412214\n",
      "matches:  125\n",
      "matchesMask:  7\n",
      "The images are not similar\n",
      "similarity score:  0.028688524590163935\n",
      "matches:  7\n",
      "The images are not similar\n",
      "similarity score:  0.011494252873563218\n",
      "matches:  3\n",
      "matchesMask:  6\n",
      "The images are not similar\n",
      "similarity score:  0.013574660633484163\n",
      "matches:  6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "images = glob.glob(\"C:/Users/marwa/Downloads/CV Labs/assignment data-20240329T203755Z-001/assignment data/*\")\n",
    "print(images)\n",
    "a_images = [img for img in images if img.endswith(\"a.jpeg\")]\n",
    "b_images = [img for img in images if img.endswith(\"b.jpeg\")]\n",
    "c_images = [img for img in images if img.endswith(\"c.png\")]\n",
    "\n",
    "a_images.sort()\n",
    "b_images.sort()\n",
    "c_images.sort()\n",
    "max_length = max(len(a_images), len(b_images), len(c_images))\n",
    "for i in range(max_length):\n",
    "    if i < len(a_images):\n",
    "        img_a = a_images[i]\n",
    "        #imageA = cv2.imread(img_a,cv2.IMREAD_UNCHANGED)\n",
    "   \n",
    "\n",
    "    if i < len(b_images):\n",
    "        img_b = b_images[i]\n",
    "        #imageB = cv2.imread(img_b,cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "\n",
    "    if i < len(c_images):\n",
    "        img_c = c_images[i]\n",
    "        #imageC = cv2.imread(img_c,cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "\n",
    "# Process images\n",
    "\n",
    "    image_number_a = int(''.join(filter(str.isdigit, img_a)))\n",
    "    image_number_b = int(''.join(filter(str.isdigit, img_b)))\n",
    "    image_number_c = int(''.join(filter(str.isdigit, img_c)))\n",
    "    if image_number_a == image_number_b == image_number_c:\n",
    "\n",
    "            ComputeMatches(img_a,img_b)\n",
    "            ComputeMatches(img_a,img_c)\n",
    "            ComputeMatches(img_b,img_c)\n",
    "    else:\n",
    "        ComputeMatches(img_a,img_b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
